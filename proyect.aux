\relax 
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\catcode `'\active 
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {chapter}{\'Indice general}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{{\'I}ndice de cuadros}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\'{I}ndice de figuras}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Definici\'on de objetivos}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{defobjetivos}{{1}{1}}
\citation{McCulloch1943}
\citation{Goodfellow2016}
\citation{Widrow2015}
\citation{Goodfellow2016}
\citation{Rosenblatt1958}
\citation{Minsky1969}
\citation{Goodfellow2016}
\citation{Hinton1986}
\citation{Rumelhart1986}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}An\'alisis de antecedentes}{2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{analanteced}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Red Neuronal Artificial}{2}\protected@file@percent }
\newlabel{sec:redneuronal}{{2.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Introducción a Redes Neuronales Artificiales}{2}\protected@file@percent }
\newlabel{subsec:nn_intro}{{2.1.1}{2}}
\citation{Hinton2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Neurona artifical}{3}\protected@file@percent }
\newlabel{subsec:neurona_artificial}{{2.1.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Neurona artificial genérica\relax }}{3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:generic_computing_unit}{{2.1}{3}}
\citation{nwankpa2018activation}
\citation{Nair2010}
\citation{nwankpa2018activation}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Representación de una Neurona Artificial con $ \DOTSB \sum@ \slimits@ x_i w_i $ como función de integración\relax }}{4}\protected@file@percent }
\newlabel{fig:neurona_artificial}{{2.2}{4}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoide}{4}\protected@file@percent }
\newlabel{subsubsec:sigmoide}{{2.1.2}{4}}
\@writefile{toc}{\contentsline {subsubsection}{Unidad Lineal Rectificada (ReLU)}{4}\protected@file@percent }
\newlabel{subsubsec:relu}{{2.1.2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Red Neuronal Artifical}{4}\protected@file@percent }
\newlabel{subsec:neural_network}{{2.1.3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Red Neuronal Artificial completamente conectada.\relax }}{5}\protected@file@percent }
\newlabel{fig:neurona_artificial}{{2.3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Descenso por Gradiente }{5}\protected@file@percent }
\newlabel{sec:gradient_descent}{{2.1.4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Ilustración del algoritmo de descenso por gradiente. $\theta _0$ y $\theta _1$ son los pesos de la ANN y $J$ la función de pérdida. Se puede observar cómo se produce un "descenso" hacia un mínimo de la función.\relax }}{6}\protected@file@percent }
\newlabel{fig:gradient_descent}{{2.4}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Red Neuronal Convolucional}{6}\protected@file@percent }
\newlabel{sec:archs}{{2.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Imagen de 4x4 px aplanada y usada como entrada en una FCNN con 4 neuronas en su única capa oculta. No se muestra su capa de salida. Imagen del curso Intro to Deep Learning with PyTorch de Udacity.\relax }}{6}\protected@file@percent }
\newlabel{fig:image_to_ANN}{{2.5}{6}}
\citation{missinglink2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Imagen de 4x4 px usada como entrada en una CNN. Ambas figuras muestran la misma arquitectura, estando en la figura de la izquierda la imagen aplanada y en la figura de la derecha se muestra la matriz 4x4 como entrada. Imágenes del curso Intro to Deep Learning with PyTorch de Udacity.\relax }}{7}\protected@file@percent }
\newlabel{fig:image_to_CNN}{{2.6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Tipos de capas}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Red Neuronal Convolucional simple en la que la imagen de un barco es clasificada.\relax }}{7}\protected@file@percent }
\newlabel{fig:simple-convnet}{{2.7}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Capa convolucional}{7}\protected@file@percent }
\citation{Li2020}
\@writefile{toc}{\contentsline {subsubsection}{Capa Pooling}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Imagen de 4x4 px usada como entrada en una CNN. Ambas figuras muestran la misma arquitectura, estando en la figura de la izquierda la imagen aplanada y en la figura de la derecha se muestra la matriz 4x4 como entrada. Imagen tomada del curso CS231n de Standford University.\relax }}{9}\protected@file@percent }
\newlabel{fig:conv-example}{{2.8}{9}}
\citation{Goodfellow2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Imagen $4\times 4$ a la que se ha aplicado un pooling de $F=2, S=2$. Cada color de la imagen de la izquierda indica las entradas del para la operación MAX, cada color de la imagen de la derecha indica la salida de dicha operación. Figura tomada del curso CS231n de Standford University.\relax }}{10}\protected@file@percent }
\newlabel{fig:maxpool}{{2.9}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Capa ReLU}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Capa FC}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Funciones de Pérdida}{10}\protected@file@percent }
\citation{Jadon2020}
\citation{Cardoso2017}
\@writefile{toc}{\contentsline {subsubsection}{Binary Cross-Entropy}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Weighted Binary Cross-Entropy}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dice Loss}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Arquitecturas usadas en segmentación}{11}\protected@file@percent }
\newlabel{sec:archs}{{2.3}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Software desarrollado}{11}\protected@file@percent }
\newlabel{sec:software}{{2.4}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Aportación Realizada}{11}\protected@file@percent }
\newlabel{sec:aportacion}{{2.5}{11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}An\'alisis de requisitos, dise\~no e implementaci\'on}{12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{requisitos}{{3}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Datos iniciales}{12}\protected@file@percent }
\newlabel{sub:datos_entrada}{{3.1}{12}}
\@writefile{toc}{\contentsline {subsubsection}{imageSequenceInterpolated}{12}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Valores mínimo y máximo de los píxeles de las imágenes de entrada.\relax }}{12}\protected@file@percent }
\newlabel{tab:prueba}{{3.1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Histograma de todos los valores\relax }}{13}\protected@file@percent }
\newlabel{fig:histogram1}{{3.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Histograma de todos los valores con el eje y limitado a 4000\relax }}{13}\protected@file@percent }
\newlabel{fig:histogram2}{{3.2}{13}}
\citation{Wolny2020}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Diseño}{14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{requisitos}{{4}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Esquema general}{14}\protected@file@percent }
\newlabel{sec:diseno-general}{{4.1}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Diseño general\relax }}{15}\protected@file@percent }
\newlabel{fig:diseno-general}{{4.1}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Preprocesado local}{16}\protected@file@percent }
\newlabel{sec:preprocesado-local}{{4.2}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Preprocesado llevado a cabo en la máquina local.\relax }}{16}\protected@file@percent }
\newlabel{fig:preprocesado}{{4.2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Reducir la resolución de la imagen de entrada}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generar las imágenes etiquetadas correctamente}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reducir el tamaño de los archivos resultantes}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Modificar el orden de las dimensiones}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Entrenamiento}{18}\protected@file@percent }
\newlabel{sec:entrenamiento}{{4.3}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \relax }}{18}\protected@file@percent }
\newlabel{fig:entrenamiento}{{4.3}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Inferencia}{19}\protected@file@percent }
\newlabel{sec:inferencia}{{4.4}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Se muestran dos métodos distintos para obtener la imagen correctamente etiquetada.\relax }}{19}\protected@file@percent }
\newlabel{fig:inferencia}{{4.4}{19}}
\citation{Ronneberger2015}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Arquitectura de las Redes Neuronales Convolucionales}{20}\protected@file@percent }
\newlabel{sec:cnn_arch}{{4.5}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Arquitectura U-Net completa.\relax }}{20}\protected@file@percent }
\newlabel{fig:unetarch-full}{{4.5}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Arquitectura U-Net completa.\relax }}{21}\protected@file@percent }
\newlabel{fig:unetarch-half}{{4.6}{21}}
\citation{Paszke2019}
\citation{Tiobe2020}
\citation{VanDerWalt2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Implementación}{22}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{implementacion}{{5}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Lenguaje y framework}{22}\protected@file@percent }
\newlabel{sec:language_framework}{{5.1}{22}}
\citation{Walt2014}
\citation{Wolny2020}
\citation{Falk2019}
\citation{Virtanen2020}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Preprocesado local}{23}\protected@file@percent }
\newlabel{sec:local_preprocessing}{{5.2}{23}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Pruebas}{24}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{pruebas}{{6}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Arquitectura U-Net media. Batch=1. Znorm. Hay sobreajuste.\relax }}{24}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.1}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Arquitectura U-Net media. Batch=1. Adam con mejores parámetros. Hay sobreajuste.\relax }}{25}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.2}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Arquitectura U-Net media. Con data augmentation. Data augmentation elimia el sobreajuste.\relax }}{26}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.3}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Arquitectura U-Net completa. Bordes. Data augmentation. Apex. El autoescalado del factor de pérdida de Apex aumenta la velocidad de entrenamiento.\relax }}{27}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.4}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Arquitectura U-Net completa. Bordes. Data augmentation. Apex.\relax }}{27}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.5}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Arquitectura U-Net completa. Bordes. Data augmentation. Apex.\relax }}{28}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.6}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces U-Net completa. Espaciado. Data augmentation. Apex\relax }}{28}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.7}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces U-Net completa. Espaciado. Data augmentation. Apex\relax }}{29}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.8}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces U-Net completa. Sin espaciado. Data augmentation. Apex\relax }}{29}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.9}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces U-Net completa. Sin espaciado. Data augmentation. Apex\relax }}{30}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.10}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces U-Net completa. Sin espaciado. Data augmentation. Apex\relax }}{30}\protected@file@percent }
\newlabel{fig:unetarch-half}{{6.11}{30}}
\bibstyle{apacite}
\bibdata{pfcbib}
\bibcite{Falk2019}{\citeauthoryear {Falk\ \BOthers {.}}{Falk\ \BOthers {.}}{{\APACyear {2019}}}}
\APACbibcite{Falk2019}{\citeauthoryear {Falk\ \BOthers {.}}{Falk\ \BOthers {.}}{{\APACyear {2019}}}}
\bibcite{Goodfellow2016}{\citeauthoryear {Goodfellow, Bengio,{}\ \BBA{} Courville}{Goodfellow\ \BOthers {.}}{{\APACyear {2016}}}}
\APACbibcite{Goodfellow2016}{\citeauthoryear {Goodfellow, Bengio,{}\ \BBA{} Courville}{Goodfellow\ \BOthers {.}}{{\APACyear {2016}}}}
\bibcite{Hinton2006}{\citeauthoryear {G.\unhbox \voidb@x \nobreak  \ Hinton, Osindero,{}\ \BBA{} Teh}{G.\unhbox \voidb@x \nobreak  \ Hinton\ \BOthers {.}}{{\APACyear {2006}}}}
\APACbibcite{Hinton2006}{\citeauthoryear {G.\unhbox \voidb@x \nobreak  \ Hinton, Osindero,{}\ \BBA{} Teh}{G.\unhbox \voidb@x \nobreak  \ Hinton\ \BOthers {.}}{{\APACyear {2006}}}}
\bibcite{Hinton1986}{\citeauthoryear {G\BPBI  E.\unhbox \voidb@x \nobreak  \ Hinton}{G\BPBI  E.\unhbox \voidb@x \nobreak  \ Hinton}{{\APACyear {1986}}}}
\APACbibcite{Hinton1986}{\citeauthoryear {G\BPBI  E.\unhbox \voidb@x \nobreak  \ Hinton}{G\BPBI  E.\unhbox \voidb@x \nobreak  \ Hinton}{{\APACyear {1986}}}}
\bibcite{McCulloch1943}{\citeauthoryear {McCulloch\ \BBA{} Pitts}{McCulloch\ \BBA{} Pitts}{{\APACyear {1943}}}}
\APACbibcite{McCulloch1943}{\citeauthoryear {McCulloch\ \BBA{} Pitts}{McCulloch\ \BBA{} Pitts}{{\APACyear {1943}}}}
\bibcite{Minsky1969}{\citeauthoryear {Minsky\ \BBA{} Papert}{Minsky\ \BBA{} Papert}{{\APACyear {1969}}}}
\APACbibcite{Minsky1969}{\citeauthoryear {Minsky\ \BBA{} Papert}{Minsky\ \BBA{} Papert}{{\APACyear {1969}}}}
\bibcite{Nair2010}{\citeauthoryear {Nair\ \BBA{} Hinton}{Nair\ \BBA{} Hinton}{{\APACyear {2010}}}}
\APACbibcite{Nair2010}{\citeauthoryear {Nair\ \BBA{} Hinton}{Nair\ \BBA{} Hinton}{{\APACyear {2010}}}}
\bibcite{nwankpa2018activation}{\citeauthoryear {Nwankpa, Ijomah, Gachagan,{}\ \BBA{} Marshall}{Nwankpa\ \BOthers {.}}{{\APACyear {2018}}}}
\APACbibcite{nwankpa2018activation}{\citeauthoryear {Nwankpa, Ijomah, Gachagan,{}\ \BBA{} Marshall}{Nwankpa\ \BOthers {.}}{{\APACyear {2018}}}}
\bibcite{Paszke2019}{\citeauthoryear {Paszke\ \BOthers {.}}{Paszke\ \BOthers {.}}{{\APACyear {2019}}}}
\APACbibcite{Paszke2019}{\citeauthoryear {Paszke\ \BOthers {.}}{Paszke\ \BOthers {.}}{{\APACyear {2019}}}}
\bibcite{Ronneberger2015}{\citeauthoryear {Ronneberger, Fischer,{}\ \BBA{} Brox}{Ronneberger\ \BOthers {.}}{{\APACyear {2015}}}}
\APACbibcite{Ronneberger2015}{\citeauthoryear {Ronneberger, Fischer,{}\ \BBA{} Brox}{Ronneberger\ \BOthers {.}}{{\APACyear {2015}}}}
\bibcite{Rosenblatt1958}{\citeauthoryear {Rosenblatt}{Rosenblatt}{{\APACyear {1958}}}}
\APACbibcite{Rosenblatt1958}{\citeauthoryear {Rosenblatt}{Rosenblatt}{{\APACyear {1958}}}}
\bibcite{Rumelhart1986}{\citeauthoryear {Rumelhart, Hinton,{}\ \BBA{} Williams}{Rumelhart\ \BOthers {.}}{{\APACyear {1986}}}}
\APACbibcite{Rumelhart1986}{\citeauthoryear {Rumelhart, Hinton,{}\ \BBA{} Williams}{Rumelhart\ \BOthers {.}}{{\APACyear {1986}}}}
\bibcite{Tiobe2020}{\citeauthoryear {Tiobe}{Tiobe}{{\APACyear {2020}}}}
\APACbibcite{Tiobe2020}{\citeauthoryear {Tiobe}{Tiobe}{{\APACyear {2020}}}}
\bibcite{VanDerWalt2011}{\citeauthoryear {Van Der\unhbox \voidb@x \nobreak  \ Walt, Colbert,{}\ \BBA{} Varoquaux}{Van Der\unhbox \voidb@x \nobreak  \ Walt\ \BOthers {.}}{{\APACyear {2011}}}}
\APACbibcite{VanDerWalt2011}{\citeauthoryear {Van Der\unhbox \voidb@x \nobreak  \ Walt, Colbert,{}\ \BBA{} Varoquaux}{Van Der\unhbox \voidb@x \nobreak  \ Walt\ \BOthers {.}}{{\APACyear {2011}}}}
\bibcite{Walt2014}{\citeauthoryear {van\unhbox \voidb@x \nobreak  \ der Walt\ \BOthers {.}}{van\unhbox \voidb@x \nobreak  \ der Walt\ \BOthers {.}}{{\APACyear {2014}}}}
\APACbibcite{Walt2014}{\citeauthoryear {van\unhbox \voidb@x \nobreak  \ der Walt\ \BOthers {.}}{van\unhbox \voidb@x \nobreak  \ der Walt\ \BOthers {.}}{{\APACyear {2014}}}}
\@writefile{toc}{\contentsline {chapter}{Referencias}{31}\protected@file@percent }
\bibcite{Virtanen2020}{\citeauthoryear {{Virtanen}\ \BOthers {.}}{{Virtanen}\ \BOthers {.}}{{\APACyear {2020}}}}
\APACbibcite{Virtanen2020}{\citeauthoryear {{Virtanen}\ \BOthers {.}}{{Virtanen}\ \BOthers {.}}{{\APACyear {2020}}}}
\bibcite{Widrow2015}{\citeauthoryear {Widrow\ \BBA{} Hoff}{Widrow\ \BBA{} Hoff}{{\APACyear {2015}}}}
\APACbibcite{Widrow2015}{\citeauthoryear {Widrow\ \BBA{} Hoff}{Widrow\ \BBA{} Hoff}{{\APACyear {2015}}}}
\bibcite{Wolny2020}{\citeauthoryear {Wolny\ \BOthers {.}}{Wolny\ \BOthers {.}}{{\APACyear {2020}}}}
\APACbibcite{Wolny2020}{\citeauthoryear {Wolny\ \BOthers {.}}{Wolny\ \BOthers {.}}{{\APACyear {2020}}}}
\ttl@finishall
