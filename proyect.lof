\babel@toc {spanish}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf {a} Representación de las células del tejido epitelial cuando están en una estructura plana. Se suele representar en forma de prisma. \textbf {b} Representación de las células del tejido epitelial cuando se produce un pliegue. Se suele representar en forma de tronco. \textbf {c} Geometría propuesta caracterizada por tener al menos un vértice en un plano distinto al de sus dos bases. En la figura de arriba se ven dos elementos adyacentes con forma escutoide. En la figura de abajo se ven estos elementos por separado. Las células del tejido epitelial tendrían esta geometría.\relax }}{4}{figure.caption.8}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Esta figura muestra el resultado de aplicar el procesado a la imagen 3D obtenida por microscopía, la imagen tiene las dimensiones $1024*1024*234$, seleccionándose para su representación Z=77 y Z=100. En la primera fila se muestra la imagen obtenida por microscopía y la segunda fila se muestra la obtenida al aplicar segmentación a las células. En la primera columna se muestra la capa Z=77 y en la segunda la capa Z=100.\relax }}{5}{figure.caption.9}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Neurona artificial genérica\relax }}{17}{figure.caption.12}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Representación de una Neurona Artificial con $ \DOTSB \sum@ \slimits@ x_i w_i $ como función de integración\relax }}{18}{figure.caption.13}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Red Neuronal Artificial completamente conectada.\relax }}{19}{figure.caption.14}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Ilustración del algoritmo de descenso por gradiente. $\theta _0$ y $\theta _1$ son los pesos de la ANN y $J$ la función de pérdida. Se puede observar cómo se produce un "descenso" hacia un mínimo de la función.\relax }}{20}{figure.caption.15}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Imagen de 4x4 px aplanada y usada como entrada en una FCNN con 4 neuronas en su única capa oculta. No se muestra su capa de salida. Imagen del curso Intro to Deep Learning with PyTorch de Udacity.\relax }}{21}{figure.caption.16}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Imagen de 4x4 px usada como entrada en una CNN. Ambas figuras muestran la misma arquitectura, estando en la figura de la izquierda la imagen aplanada y en la figura de la derecha se muestra la matriz 4x4 como entrada. Imágenes del curso Intro to Deep Learning with PyTorch de Udacity.\relax }}{22}{figure.caption.17}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Red Neuronal Convolucional simple en la que la imagen de un barco es clasificada.\relax }}{22}{figure.caption.18}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Capa de convolución de profundidad 2 (se usan dos filtros) con kernel de tamaño $3\times 3 \times 3$ aplicado a un volumen de entrada de tamaño $7x7x3$, volumen generado al aplicar padding de 1 px a una imagen de tamaño $5x5$ con 3 canales. El resultado es un volumen de $3x3x2$\relax }}{24}{figure.caption.19}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Imagen $4\times 4$ a la que se ha aplicado un pooling de $F=2, S=2$. Cada color de la imagen de la izquierda indica las entradas del para la operación MAX, cada color de la imagen de la derecha indica la salida de dicha operación. Figura tomada del curso CS231n de Standford University.\relax }}{25}{figure.caption.20}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Arquitectura de FCN32, FCN16 y FCN8.\relax }}{28}{figure.caption.21}%
\contentsline {figure}{\numberline {7.2}{\ignorespaces Arquitectura Deconvnet.\relax }}{29}{figure.caption.22}%
\contentsline {figure}{\numberline {7.3}{\ignorespaces Figura que ilustra las operaciones unpooling y deconvolución.\relax }}{29}{figure.caption.23}%
\contentsline {figure}{\numberline {7.4}{\ignorespaces Arquitectura original U-Net propuesta por Ronneberger et al en U-Net: Convolutional Networks for Biomedical Image Segmentation.\relax }}{30}{figure.caption.24}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {8.1}{\ignorespaces Segmentación volumétrica. (a) Segmentación de una imagen con un modelo que se ha entrenado con imágenes del mismo dataset. (b) Segmentación de una imagen con un modelo entrenado con un dataset distinto.\relax }}{33}{figure.caption.26}%
\contentsline {figure}{\numberline {8.2}{\ignorespaces Segmentación de tejido vegetal usando PlantSeg. En el primer paso se predicen los bordes de las células usando una red U-Net 3D. En el segundo paso se aplica un algoritmo de particionamiento de grafo para segmentar cada célula.\relax }}{34}{figure.caption.28}%
\contentsline {figure}{\numberline {8.3}{\ignorespaces Interfaz gráfica del programa PlantSet. Se pueden ver las distintas opciones para cada paso del procesado.\relax }}{35}{figure.caption.30}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {10.1}{\ignorespaces Métricas obtenidas al entrenar durante 10 epochs. acc\_camvid es el nº de píxeles clasificados correctamente entre el nº de píxeles totales. El tiempo es en segundos.\relax }}{40}{figure.caption.31}%
\contentsline {figure}{\numberline {10.2}{\ignorespaces Métricas obtenidas al entrenar durante 10 epochs. acc\_camvid es el nº de píxeles clasificados correctamente entre el nº de píxeles totales. El tiempo es en segundos.\relax }}{41}{figure.caption.32}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {11.1}{\ignorespaces Arquitectura U-Net reducida. Arquitectura completa (vista en \ref {sec:unet} eliminando varias capas de convolución y una de pooling. Los modelos generados por esta arquitectura serán menos fiables, pero el entrenamiento será más rápido, por lo que es útil para implementar un primer sistema.\relax }}{44}{figure.caption.36}%
\contentsline {figure}{\numberline {11.2}{\ignorespaces Pérdida de entrenamiento en cada iteración. 100 iteraciones. Se mide la pérdida media del conjunto de entrenamiento y el conjunto de validación.\relax }}{49}{figure.caption.42}%
\contentsline {figure}{\numberline {11.3}{\ignorespaces Ejemplo de segmentación del conjunto de test. Primera fila la imagen original, segunda fila segmentación objetiva, tercera fila segmentación predicha. Se muestra en cada columna Z=20, Z=25, Z=45, Z=50.\relax }}{49}{figure.caption.43}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {12.1}{\ignorespaces Pérdida de entrenamiento en cada iteración. 100 iteraciones. Se mide la pérdida media del conjunto de entrenamiento y el conjunto de validación.\relax }}{52}{figure.caption.45}%
\contentsline {figure}{\numberline {12.2}{\ignorespaces Ejemplo de segmentación del conjunto de test. Fila 1 imagen original, fila 2 segmentación objetiva, fila 3 segmentación predicha. Columnas Z=20, Z=25, Z=45, Z=50.\relax }}{52}{figure.caption.46}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {13.1}{\ignorespaces Pérdida de entrenamiento en cada iteración. 200 iteraciones. Se puede ver claramente cómo se produce sobreajuste.\relax }}{55}{figure.caption.47}%
\contentsline {figure}{\numberline {13.2}{\ignorespaces Pérdida de entrenamiento. 100 iteraciones.\relax }}{56}{figure.caption.49}%
\contentsline {figure}{\numberline {13.3}{\ignorespaces Ejemplo de segmentación del conjunto de test. Fila 1 imagen original, fila 2 segmentación objetiva, fila 3 segmentación predicha. Columnas Z=20, Z=25, Z=45, Z=50.\relax }}{56}{figure.caption.50}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {17.1}{\ignorespaces Diseño general\relax }}{61}{figure.caption.51}%
\contentsline {figure}{\numberline {17.2}{\ignorespaces Preprocesado llevado a cabo en la máquina local.\relax }}{62}{figure.caption.52}%
\contentsline {figure}{\numberline {17.3}{\ignorespaces Pasos llevados a cabo en el entrenamiento\relax }}{63}{figure.caption.55}%
\contentsline {figure}{\numberline {17.4}{\ignorespaces Se muestran dos métodos distintos para obtener la imagen correctamente etiquetada.\relax }}{64}{figure.caption.56}%
\contentsline {figure}{\numberline {17.5}{\ignorespaces Arquitectura U-Net completa.\relax }}{65}{figure.caption.57}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {20.1}{\ignorespaces Modelo miniunet2.1. 100 epochs. Se usa MiniUnet3D. Imagen objetivo con espaciado entre células. Sin data augmentation.\relax }}{73}{figure.caption.63}%
\contentsline {figure}{\numberline {20.2}{\ignorespaces Modelo unet4.1. 200 epochs. Imagen objetivo con espaciado entre células. Sin data augmentation.\relax }}{73}{figure.caption.63}%
\contentsline {figure}{\numberline {20.3}{\ignorespaces Modelo unet4.13. 200 epochs. Imagen objetivo con espaciado entre células. Sin data augmentation.\relax }}{74}{figure.caption.65}%
\contentsline {figure}{\numberline {20.4}{\ignorespaces Modelo unet4.8. 200 epochs. Imagen objetivo con espaciado entre células. Con data augmentation.\relax }}{74}{figure.caption.65}%
\contentsline {figure}{\numberline {20.5}{\ignorespaces Modelo unet4.8. 200 epochs. Imagen objetivo con espaciado entre células. Con data augmentation. Sin Apex\relax }}{75}{figure.caption.67}%
\contentsline {figure}{\numberline {20.6}{\ignorespaces Modelo unet5.2. 200 epochs. Imagen objetivo con espaciado entre células. Con data augmentation. Con Apex.\relax }}{75}{figure.caption.67}%
\contentsline {figure}{\numberline {20.7}{\ignorespaces Modelo unet6t. 100 epochs. Imagen objetivo con espaciado entre células. Con data augmentation. Pérdida Dice. Sin postprocesado. Primera fila imagen de entrada. Segunda fila segmentación objetivo. Tercera fila predicción. Z=20,25,45,50 en las columnas. IoU 0.72\relax }}{76}{figure.caption.69}%
\contentsline {figure}{\numberline {20.8}{\ignorespaces Modelo unet6t. 100 epochs. Imagen objetivo con espaciado entre células. Con data augmentation. Sin postprocesado.\relax }}{76}{figure.caption.69}%
\contentsline {figure}{\numberline {20.9}{\ignorespaces Modelo unet6b. 100 epochs. Imagen objetivo bordes de células. Con data augmentation. Pérdida Dice. Sin postprocesado. Primera fila imagen de entrada. Segunda fila segmentación objetivo. Tercera fila predicción. Z=20,25,45,50 en las columnas. IoU 0.84\relax }}{77}{figure.caption.71}%
\contentsline {figure}{\numberline {20.10}{\ignorespaces Modelo unet6b. 100 epochs. Imagen objetivo bordes de células. Con data augmentation. Pérdida Dice. Sin postprocesado.\relax }}{77}{figure.caption.71}%
\contentsline {figure}{\numberline {20.11}{\ignorespaces DT Watershed aplicado a la salida del modelo unet6b. Primera fila bordes. Segunda fila transformación de la distancia. Filtro gaussiano. Cuarta fila watershed con mínimos locales como semilla. Z=20,25,45,50 en las columnas.\relax }}{78}{figure.caption.73}%
\contentsline {figure}{\numberline {20.12}{\ignorespaces Modelo unet6b. 100 epochs. Imagen objetivo bordes de células. Con data augmentation. Pérdida Dice. Componentes conexas con etiquetas distintas. IoU 0.72\relax }}{79}{figure.caption.75}%
\contentsline {figure}{\numberline {20.13}{\ignorespaces DT Watershed aplicado a la salida del modelo unet6b. IoU 0.70\relax }}{79}{figure.caption.75}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsfinish 
\contentsfinish 
