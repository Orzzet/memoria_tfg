\chapter{Manual}\label{manual}

El proyecto está disponible en el siguiente enlace:

\url{https://github.com/Orzzet/segmentacion_celular_unet3d}. 

\section{Instalación}

Prerequisitos:

\begin{itemize}
\item Sistema operativo Linux.
\item CUDA \url{https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html}
\item Python 3.5+ \url{https://www.python.org/downloads/}
\item (Opcional) Jupyter Notebook \url{https://jupyter.readthedocs.io/en/latest/install.html} o un software que pueda ejectur Notebooks.
\end{itemize}


Instalación:

\begin{verbatim}

pip install torch torchvision
git clone https://github.com/Orzzet/3d-cell-segmentation.git
cd 3d-cell-segmentation
pip install requirements.txt

\end{verbatim}

\section{Guía de uso}
El proyecto puede utilizarse por consola de comandos o por Notebooks.

\subsubsection{Consola de comandos}

Para facilitar los parámetros de configuración se usa un archivo .yaml (como el archivo \url{https://github.com/Orzzet/3d-cell-segmentation/blob/master/config.yaml}) con la siguiente estructura:
\begin{verbatim}
# train, test o predict
job: "test" 
# Cociente por el que se divide cada dimensión.
dim_size_reduction: [1,1,1]
# Nombre del dataset etiquetado dentro del archivo .h5
target_mode: "target" 
# True usa gpu, False usa cpu
gpu: True
# Nombre del modelo (sin extensión ni path)
model_name: "prueba"
# Path a la carpeta donde se guardan los modelos 
models_folder: "./"
# Arquitectura a usar. UNet3D o MiniUNet3D. 
arch: "UNet3D"
# True usa precisión mixta, False no. 
AMP: True

# Si job=train:
train_path: "data/cells/0.25z 0.125x 0.125y/train/"
valid_path: "data/cells/0.25z 0.125x 0.125y/valid/"
loss_function: "dice"
n_epochs: 100

# Si job=test:
test_path: "data/cells/0.25z 0.125x 0.125y/test/"

# Si job=predict:
input_path: "data/cells/0.25z 0.125x 0.125y/test/"
output_path: "data/cells/0.25z 0.125x 0.125y/test/prediction"
\end{verbatim}

Después de configurar este archivo, abrir un terminal, navegar hacia la raíz del proyecto y escribir:

\begin{verbatim}
python main.py "PATH/TO/YAML"
\end{verbatim}

Donde PATH/TO/YAML es el path hacia del archivo de configuración .yaml

\subsubsection{Jupyter Notebook}

Será necesario haber instalado el prerequisito opcional Jupyter Notebook. Tras esto ejecutar Jupyter Notebook y navegar hasta la carpeta raíz del proyect.

Para entrenar un nuevo modelo usar el notebook 1\_Entrenamiento.ipynb. Hay que configurar los siguientes parámetros, siendo estos parámetros los mismos que los usados por consola de comandos:

\begin{verbatim}
DIM_SIZE_REDUCTION = (1,1,1)
MODELS_FOLDER = "../models/"
TARGET_MODE = 'target'
model_name: "prueba"
n_epochs = 300
train_path = '../data/cells/0.25z 0.125x 0.125y/train/'
valid_path = '../data/cells/0.25z 0.125x 0.125y/valid/'
arch = "MiniUNet3D"
loss_function = "dice"
AMP = False
\end{verbatim}

Tras configurar estos parámetros, ejecutar todas las celdas. Si el nombre del modelo ya existe en el path de modelos indicado, se reanudará el entrenamiento por el último epoch entrenado.

Para calcular métricas de un modelo, usar el notebook 2\_Test.ipynb. Para usar este notebook hay que configurar los mismos parámetros que en el entrenamiento, a excepción que en este notebook hay que indicar el path hacia el conjunto de test:\\

\verb|test_path = '../data/cells/0.25z 0.125x 0.125y/test/'|\\

Para predecir una segmentación, usar el notebook 3\_Infe.ipynb. Hay que indicar el directorio donde se encuentran las imágenes originales y el directorio donde guardar los etiquetados obtenidos. La predicción se guardará en un archivo con formato .h5, dentro de este archivo se guardará en ``prediction''. Además se mostrarán 4 capas de la segmentación obtenida de cada imagen de entrada.