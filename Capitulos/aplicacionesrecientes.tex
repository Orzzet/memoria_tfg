\chapter{Aplicaciones recientes}\label{apps}

En esta sección se describirán dos aplicaciones recientes en las que se realiza segmentación celular usando la arquitectura U-Net. Primero se describirá el proyecto en general, luego se definirá brevemente el algoritmo de segmentación seguido dividiendo las operaciones en: preprocesado (preparar los datos para usarlos en el modelo U-Net, procesado (características del modelo) y postprocesado (operaciones posteriores al resultado dado por el modelo), después se mostrará resultados obtenidos y por último mencionará el software resultante de estas investigaciones.

\section{U-Net para conteo, detección y morfometría, detección y morfometría de células. (2019)}\label{sec:app1}
\subsection{Proyecto}\label{apps1_proyect}

Ha sido desarrollado por investigadores de la Universidad de Friburgo (Alemania) en colaboración con la Universidad de Berna (Suiza) y la Universidad de París V Descartes (Francia) \cite{Falk2019}. El coautor designado es Olaf Ronneberger, uno de los principales contribuyentes en la creación de la arquitectura U-Net \cite{Ronneberger2015}.

En este proyecto se aplica la arquitectura U-Net para solucionar el problema del tratamiento de imagen que hay que realizar al gran volumen de datos originados por microscopios antes de que puedan ser analizados por investigadores.

\subsection{Pipeline}\label{apps1_pipeline}

\cuadro{|c|c|c|}{Pipeline que siguen los datos de inicio a fin. GT significa \textit{groundtruth} y se refiere a la imagen ya segmentada. IM es la imagen de entrada.}{tab:prueba}{
Preprocesado & Procesado & Postprocesado \\ 
\hline
GT:Espaciado de 1 vóxel entre células  	& U-Net & Ninguno \\
GT:Células etiqueta 1, fondo 0  		& Función de pérdida: & \\
IMyGT:Troceo de imagen a 236x236x100 vx & -Entropía Cruzada con Pesos & \\
IMyGT:Data Augmentation: 				& -Peso alto en espaciado entre células & \\
-Rotación 								& Optimizador ADAM: & \\
-Deformación suave 						& -Learning rate $10^{-5}$ $\beta_1:0.9$, $\beta_2:0.999$ & \\
-Incremento de intensidad 				& 150000 Iteraciones & \\
}

La segmentación semántica etiqueta cada vóxel con la clase correspondiente, no distingue entre distintas instancias de un mismo objeto si estos están en contacto. Para conseguir esta distinción entre células se ha aplicado un espaciado de un vóxel alrededor de cada célula en la imagen segmentada a mano. De esta forma se podrá comprobar la forma de todas las células y se podrán contabilizar.

Para que la imagen ocupe menos memoria y el entrenamiento sea más rápido, se ha dividido la imagen en trozos de 236x236x100. 

Se usa data augmentation (aumentación de datos) tanto en la imagen de entrada como en la imagen objetivo para mejorar el aprendizaje. Gracias a esto en este proyecto se sostiene que no son necesarias más de 10 imágenes anotadas para el correcto entrenamiento de un modelo.

Respecto al modelo entrenado, se ha usado como función de pérdida la entropía cruzada con pesos a nivel de vóxel. Esto quiere decir que cada vóxel en cada imágen va a tener un peso propio. El peso de cada vóxel viene dado por la siguiente fórmula:
\begin{equation}
w(x):=w^{'}_{bal}+\lambda w_{sep}
\end{equation}

Donde $\lambda \epsilon R_{\geq}0$ controla la importancia de la separación de instancia. $w^{'}_{bal}$ y $w_{sep}$
son calculados de la siguiente forma:

\begin{equation}
w^{'}_{bal}(x):= \left \{ \begin{matrix} 1 & y(x)>0
\\ v_{bal}+(1-v_{bal})*exp(-\frac{d^2_1(x)}{2\sigma^2_{bal}}) & y(x)=0
\\ 0 & y(x) desconocido \end{matrix}\right. 
\end{equation}

Donde $d_1$ es la distancia hacia la instancia de célula más cercana, $v_{bal}\epsilon [0,1]$ es un factor se usa para reducir la importancia de los vóxeles de fondo y $\sigma_{bal}$ es la desviación estándar deseada.

\begin{equation}
w_{sep}(x) := exp(-\frac{(d_1(x)+d_2(x))^2}{2\sigma_{sep}^2})
\end{equation}

Donde $d_2$ es la distancia a la segunda instancia de célula más cercana y $\sigma_{sep}$ es la desviación estándar deseada. 


\subsection{Resultados}\label{app1_results}

\figura{1}{img/unet-morf-example}{Segmentación volumétrica. (a) Segmentación de una imagen con un modelo que se ha entrenado con imágenes del mismo dataset. (b) Segmentación de una imagen con un modelo entrenado con un dataset distinto.}{fig:unet-morf-example}{}

La métrica utilizada para cuantificar la calidad del resultado es intersección sobre unión (IoU).

\begin{equation}
M_{IoU}(A, B) := \frac{|A\cap B|}{|A\cup B|}
\end{equation}

Donde $A$ es el conjunto de vóxeles pertenecientes a la imagen perfectamente etiquetada y $B$ el conjunto de vóxeles pertenecientes a la predicción. Un $M_{IoU}\epsilon[0,1]$ igual a 1 equivale a una predicción perfecta mientras que igual a 0 equivale a una predicción en la que ningún vóxel coincide.
Acorde a los experimentos realizados, se tomará un valor $\sim0.7$ como una buena segmentación, siendo $\sim0.9$ una segmentación equivalente a la humana.

Se hicieron varios experimentos, alcanzando siempre un $M_{IoU}>0.8$ para datos volumétricos.

\subsection{Software}\label{app1_software}

Este algoritmo ha sido implementado como un plugin de FIJI \cite{Schindelin2012}, una herramienta opensource para procesamiento de imágenes. Este plugin viene con modelos preentrenados para la segmentación de células y está disponible como repositorio oficial de imageJ \textit{http://sites.imagej.net/Falk/plugins/}, con código fuente incluido.

El framework usado como backend es \textbf{caffe} \cite{Jia2014}, que será necesario instalar previamente. Los binarios de caffe así como modelos entrenados para segmentación 2D y 3D están disponibles en \textit{https://lmb.informatik.uni-freiburg.de/resources/opensource/unet}

\section{Segmentación 3D precisa y versátil de tejido vegetal a resolución celular. (2020)}\label{sec:app2}


\subsection{Proyecto}\label{app2_proyect}

Ha sido realizado por investigadores de la universidad de Heidelberg (Alemania), colaborando con la Universidad Técnica de Munich (Alemania) y la Universidad de Warwick (UK). Los coautores son Adrian Wolny y Lorenzo Cerrone.\cite{Wolny2020}

Este proyecto está hecho con la idea de utilizar las últimas y mejores técnicas para segmentación precisa de datos volumétricos a nivel celular y hacerlo accesible a personas no expertas en la materia de visión por ordenador. El resultado de este proyecto es el software PlantSeg.

\subsection{Pipeline}\label{app2_pipeline}

\cuadro{|c|c|c|}{Pipeline que siguen los datos de inicio a fin. GT significa \textit{groundtruth} y se refiere a la imagen ya segmentada. IM es la imagen de entrada.}{tab:prueba}{
Preprocesado & Procesado & Postprocesado \\ 
\hline
GT:Bordes con 2 vóxeles de anchura		& U-Net 								& Transformada de la distancia \\
GT:Desenfoque Gaussiano			  	   	& Funciónes de pérdida probadas: 		& Detectado de centroides\\
IM y GT:Data Augmentation 				& -Entropía Cruzada Binaria  			& Algoritmo watershed\\
- Volteo Horizontal y Vertical			& -Pérdida Dice							& Grafo de adyacencia\\
- Rotación en plano XY					& Optimizador ADAM:						& Particionamiento de grafo\\
- Deformación elástica					& -Learning rate $10^{-5}$				& \\
IM: Noise Augmentation		 			& -$\beta_1:0.9$, $\beta_2:0.999$		& \\
IM,GT:Troceo de imagen a 170x170x80 vx	& 100000 iteraciones					& \\
}

En el preprocesado, se parte de una imagen con etiquetado perfecto y se le aplica la función \textit{find\_ boundaries} de la librería scikit \cite{Pedregosa2011} \cite{Walt2014} obteniendo los bordes de las células con 2 vóxeles de anchura. A la imagen con los bordes se le aplica un desenfoque Gaussiano para reducir los componentes de alta frecuencia, lo que ayuda a prevenir el sobreajuste. Luego se aplica varias técnicas de \textit{data augmentation} en el espacio a la imagen de entrada y a la imagen de bordes. Tras esto se aplica \textit{noise augmentation} a la imagen de entrada. Por último se divide la imagen en trozos de 170x170x80 vx.

En el procesado, se usa una arquitectura U-Net y se prueba con Entropía Cruzada Binaria y con Pérdida Dice, usando un optimizador ADAM en ambos casos.

En el postprocesado, se parte de la imagen con la probabilidad de que cada vóxel pertenezca al borde de la imagen, se aplica un umbral para binarizar la imagen, donde cualquier probabilidad $>0.4$ se considera borde. A la imagen binarizada se le aplica la transformada de la distancia, dando a cada vóxel de fondo un valor igual al vóxel de borde más cercano. A esta imagen se le aplica un suavizado gaussiano con $\sigma = 2.0$ y se calculan los mínimos locales para seleccionar las semillas. Estas semillas son usadas en el algoritmo watershed para obtener la segmentación final.

El algoritmo watershed trata el valor de los vóxeles como si describiese una topología.
\begin{enumerate}
\item Se colocan unas semillas iniciales, desde aquí se empezará la inundación. Cada semilla tendrá una etiqueta distinta.
\item Los vecinos de cada vóxel etiquetado se insertan en una cola prioritaria teniendo más prioridad aquellos con un valor más bajo.
\item El vóxel con más prioridad sale de la cola, si todos sus vecinos etiquetados tienen la misma etiqueta, se le pone esa etiqueta. Todos los nuevos vecinos sin marcar son puestos en la cola prioritaria.
\item Se vuelve al paso 3 hasta que se vacía la cola.
\end{enumerate}

\subsection{Resultados}\label{app2_results}

\figura{1}{img/wolny-resultados}{Segmentación de tejido vegetal usando PlantSeg. En el primer paso se predicen los bordes de las células usando una red U-Net 3D. En el segundo paso se aplica un algoritmo de particionamiento de grafo para segmentar cada célula.}{fig:wolny-resultados}{}

Para la etapa de la predicción de bordes se han usado tres métricas:
\begin{itemize}
\item Precisión: Nº vóxeles correctamente etiquetados como borde en la predicción entre el nº de vóxeles etiquetados como borde en la predicción.
\item Exhaustividad: Nº de vóxeles etiquetados correctamente en la predicción entre el nº de vóxeles etiquetados como bordes en la imagen con perfecto etiquetado.
\item Puntuación F1: $F1=2*\frac{Precision * Exhaustividad}{Precision+Exhaustividad}$
\end{itemize}

Para estas 3 métricas mientras más alto sea el valor mejor, siendo $1$ la medida perfecta y $0$ la peor.

Para la segmentación final se ha usado la variación de información (VOI), definida como:
\begin{equation}
VOI = H(seg|GT) + H(GT|seg)
\end{equation}

Donde $H$ es la entropía condicional, $seg$ es la predicción de la segmentación y $GT$ es la segmentación perfecta. Para esta métrica mientras más bajo sea el valor mejor, siendo 0 el valor perfecto.

Se han han realizado muchas pruebas en este proyecto, en la tabla \ref{tab:plant-seg-resultados} se puede ver dos pruebas en las que se compara la entropía cruzada binaria y la pérdida Dice.

\cuadro{|c|c|c|c|}{Pruebas relevantes realizadas.}{tab:plant-seg-resultados}{
Función de pérdida 			& Precisión 		& Exhaustividad 	& Puntuación F1\\ 
\hline
Entropía Cruzada Binaria	& 0.806 $\pm$ 0.071	& 0.799 $\pm$ 0.028 & 0.800 $\pm$ 0.036 \\
Pérdida Dice				& 0.744 $\pm$ 0.096 & 0.933 $\pm$ 0.017 & 0.824 $\pm$ 0.062	\\
}

Como se ven en los resultados parece que la pérdida Dice es ligeramente superior aunque no por mucho.

\subsection{Software}\label{app2_software}

PlantSeg es un programa que puede ser ejecutado por una interfaz gráfica o por línea de comandos. Dispone de todos los modelos preentenados en este proyecto, así como de todas las opciones para entrenar nuevos modelos o hacer inferencia. El software con las instrucciones para su uso están disponibles en \textit{https://github.com/hci-unihd/plant-seg}.

\figura{1}{img/plantseg-software}{Interfaz gráfica del programa PlantSet. Se pueden ver las distintas opciones para cada paso del procesado.}{fig:plantseg-software}{}
