\chapter{Mejora 4: Normalización}\label{znormalization}

Aunque en los últimos resultados ya se empieza a ver una segmentación adecuada de las células, se está etiquetando incorrectamente el fondo como célula.

Tras estudiar la imagen original se ha llegado a la conclusión de que podría deberse a la diferencia en la intensidad de los vóxeles. En el cuadro \ref{cuadro:intensidad_min_max} se muestra la intensidad mínima y máxima de las 20 imágenes que componen el dataset. Puede ser un problema que haya vóxeles con valor 60000 y otros con valor 1, ya que los que tengan un valor más alto tendrán mucho más peso en la red convolucional. Lo interesante en la red convolucional será encontrar patrones estructurales, no patrones relacionados con una diferencia alta de intensidad.

\cuadro{|r|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}{Valores mínimo y máximo de los píxeles de las imágenes de entrada.}{cuadro:intensidad_min_max}{
35.0 & 32.0 & 33.0 & 0.0 & 31.0 & 24.0 & 19.0 & 0.0 & 0.0 & 24.0 \\ 
4095.0 & 4095.0 & 4095.0 & 65535.0 & 4069.0 & 4095.0 & 4095.0 & 65535.0 & 65535.0 & 4095.0 \\
\hline
22.0 & 22.0 & 23.0 & 30.0 & 31.0 & 30.0 & 25.0 & 30.0 & 23.0 & 19.0 \\
4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 & 4095.0 \\
}

Para ignorar esta diferencia alta de intensidad y centrarnos en las diferencias estructurales se puede recurrir a la normalización. En concreto se probarán dos normalizaciones distintas: el cambio a escala $[0,1]$ y por distribución normal (puntuación tipificada).

El cambio a escala $[0,1]$ es algo habitual en machine learning para evitar que se realicen operaciones con números muy altos, facilitando el cálculo de los gradientes. Cada vóxel pasará a tener el siguiente valor:
\begin{equation}
v_i^{'} = \frac{v_i - v_{min}}{v_{max}-v_{min}}
\end{equation}

Donde $v_i^{'}$ el nuevo valor del vóxel, $v_i$ el valor actual, $v_{min}$ el valor mínimo en toda la imagen y $v_{max}$ el valor máximo en toda la imagen.

La puntuación tipificada hace que los valores estén más cerca entre ellos, útil para cuando hay datos muy dispersos. Su fórmula es:
\begin{equation}
v_i^{'} = \frac{v_i - \mu}{\rho}
\end{equation}

Donde $v_i^{'}$ es el nuevo valor del vóxel, $v_i$ es el valor actual, $\mu$ es la media de los valores de la imagen y $\rho$ es la desviación estándar. \cite{znormalization}

Para decidir qué técnica usar se van a comparar los histogramas.

\figura{1}{img/pruebas/comparacion_normaliz}{Izquierda: Normalización tipificada. Derecha: Cambio a escala $[0,1]$.}{fig:comparacion_normaliz}{}{Histogramas de aplicar la normalización tipificada y el cambio a escala }

En la figura \ref{fig:comparacion_normaliz} se muestran los dos histogramas. En el histograma del cambio a escala se puede ver cómo los vóxeles sólo tienen valores entre $0$ y $1$. Aún así se observa que la mayoría de los valores están en la zona de menor intensidad, lo que se soluciona con la normalización tipificada. Por lo tanto es esta última la que se implementará.

Aunque las operaciones matemáticas son simples, se utilizará TorchIO \cite{PerezGarcia2020} para implementar la normalización tipificada, ya que facilita el uso de otras posibles operaciones a los datos sin modificar mucho el código. TorchIO es una librería que contiene herramientas para trabajar con datos 3D especializadas para imágenes médicas. Se ha utilizado la función \textit{transforms.ZNormalization()} en la imagen de entrada.

\section{Resultados}\label{sec:apex_resultados}

\cuadro{|c|c|c|}{Métricas normalización.}{tab:metricas_5}{
IoU fondo & IoU células\\ 
\hline
0.9811 & 0.7224\\
}

\figura{0.8}{img/pruebas/sistema_5_normalizacion_perdidas}{Pérdida de entrenamiento. 100 iteraciones.}{fig:sistema_5_normalizacion_perdidas}{}{Pérdida de entrenamiento y validación de sistema con normalización.}

\figura{0.8}{img/pruebas/sistema_5_normalizacion_visual}{Ejemplo de segmentación del conjunto de test. Fila 1 imagen original, fila 2 segmentación objetivo, fila 3 segmentación predicha. Columnas Z=20, Z=25, Z=45, Z=50.}{fig:sistema_5_normalizacion_visual}{}{Ejemplo de segmentación de sistema con normalización.}

Por primera vez se ha conseguido una $IoU > 0.7$ para las células, siendo la $IoU$ del fondo casi perfecto. Al normalizar los datos la red convolucional ha podido encontrar correctamente los patrones estructurales en la imagen original para poder llegar a la segmentación objetivo.

Ya se ha llegado a un $IoU > 0.7$, que era el objetivo impuesto. Los capítulos posteriores estarán orientados a reducir el consumo de memoria para aumentar la resolución de las imágenes de entrada, buscar métodos alternativos o postprocesado.